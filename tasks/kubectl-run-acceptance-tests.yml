platform: linux

image_resource:
  type: docker-image
  source:
    repository: eu.gcr.io/census-gcr/gcloud-kubectl

params:
  SERVICE_ACCOUNT_JSON:
  GCP_PROJECT_NAME:
  KUBERNETES_CLUSTER:
  ACCEPTANCE_TESTS_IMAGE:
  BATCH_RUNNER_CONFIG:

inputs:
- name: acceptance-tests-repo
- name: batch-runner-repo

run:
  path: bash
  args:
    - -exc
    - |
      cat >~/gcloud-service-key.json <<EOL
      $SERVICE_ACCOUNT_JSON
      EOL

      # Use gcloud service account to configure kubectl
      gcloud auth activate-service-account --key-file ~/gcloud-service-key.json
      gcloud container clusters get-credentials ${KUBERNETES_CLUSTER} --zone europe-west2 --project ${GCP_PROJECT_NAME}

      # Create an acceptance tests pod and run the acceptance tests in it
      # Env vars have to passed one by one as a --env flag each
      # The sleep is to give kubectl time to attach properly, otherwise the first few log lines are lost
      kubectl run acceptance-tests -it --command --rm --quiet \
      --generator=run-pod/v1 \
      --image=${ACCEPTANCE_TESTS_IMAGE} \
      --restart=Never \
      $(while read env; do echo --env=${env}; done < acceptance-tests-repo/kubernetes.env) \
      --env=SFTP_HOST=$(kubectl get secret sftp-ssh-credentials -o=jsonpath="{.data.host}" | base64 --decode) \
      --env=SFTP_USERNAME=$(kubectl get secret sftp-ssh-credentials -o=jsonpath="{.data.username}" | base64 --decode) \
      --env=SFTP_KEY=$(kubectl get secret sftp-ssh-credentials -o=jsonpath="{.data.private-key}") \
      --env=SFTP_PASSPHRASE=$(kubectl get secret sftp-ssh-credentials -o=jsonpath="{.data.passphrase}" | base64 --decode) \
      --env=SFTP_PPO_DIRECTORY=$(kubectl get configmap project-config -o=jsonpath="{.data.sftp-ppo-supplier-directory}") \
      --env=SFTP_QM_DIRECTORY=$(kubectl get configmap project-config -o=jsonpath="{.data.sftp-qm-supplier-directory}") \
      --env=REDIS_SERVICE_HOST=$(kubectl get configmap redis-config -o=jsonpath="{.data.redis-host}") \
      --env=REDIS_SERVICE_PORT=$(kubectl get configmap redis-config -o=jsonpath="{.data.redis-port}") \
      --env=RECEIPT_TOPIC_PROJECT=$(kubectl get configmap pubsub-config -o=jsonpath="{.data.receipt-topic-project-id}") \
      --env=RECEIPT_TOPIC_ID=$(kubectl get configmap pubsub-config -o=jsonpath="{.data.receipt-topic-name}") \
      --env=OFFLINE_RECEIPT_TOPIC_PROJECT=$(kubectl get configmap project-config -o=jsonpath="{.data.project-name}") \
      --env=OFFLINE_RECEIPT_TOPIC_ID=offline-receipt-topic \
      --env=PPO_UNDELIVERED_PROJECT_ID=$(kubectl get configmap project-config -o=jsonpath="{.data.project-name}") \
      --env=PPO_UNDELIVERED_TOPIC_NAME=ppo-undelivered-topic \
      --env=QM_UNDELIVERED_PROJECT_ID=$(kubectl get configmap project-config -o=jsonpath="{.data.project-name}") \
      --env=QM_UNDELIVERED_TOPIC_NAME=qm-undelivered-topic \
      --env=GOOGLE_SERVICE_ACCOUNT_JSON=$(kubectl get secret pubsub-credentials -o=jsonpath="{.data['service-account-key\.json']}") \
      --env=GOOGLE_APPLICATION_CREDENTIALS="/app/service-account-key.json" \
      --env=RABBITMQ_USER=$(kubectl get secret rabbitmq -o=jsonpath="{.data.rabbitmq-username}" | base64 --decode) \
      --env=RABBITMQ_PASSWORD=$(kubectl get secret rabbitmq -o=jsonpath="{.data.rabbitmq-password}" | base64 --decode) \
      --env=RABBITMQ_HTTP_PORT=15672 \
      --env=NOTIFY_STUB_HOST=notify-stub \
      --env=NOTIFY_STUB_PORT=80 \
      --env=EXCEPTIONMANAGER_CONNECTION_HOST=exception-manager \
      --env=EXCEPTIONMANAGER_CONNECTION_PORT=80 \
      -- /bin/bash -c "sleep 2; behave acceptance_tests/features --tags=~@local-docker"


      # Run acceptance tests for unaddressed batch
      # Pre-delete to avoid unintentionally running with an old image
      kubectl delete deploy qid-batch-runner --force --now || true
      kubectl apply -f ${BATCH_RUNNER_CONFIG}
      kubectl rollout status deploy qid-batch-runner --watch=true
      kubectl exec -it $(kubectl get pods -o name | grep -m1 qid-batch-runner | cut -d'/' -f 2) \
      -- /bin/bash /app/run_acceptance_tests.sh
      kubectl delete deploy qid-batch-runner --force --now
